{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center'> Importing the libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import spacy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2 \n",
    "import multiprocessing as mp\n",
    "import imp\n",
    "import threading\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center'> Preparing the dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_traindata = pd.read_csv('text_dataset_train.tsv',sep='\\t')\n",
    "multi_validata = pd.read_csv('text_dataset_val.tsv',sep='\\t')\n",
    "multi_testdata = pd.read_csv('text_dataset_test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = multi_traindata[multi_traindata['title'].notna()]\n",
    "\n",
    "valid_data = multi_validata[multi_validata['title'].notna()]\n",
    "\n",
    "test_data = multi_testdata[multi_testdata['title'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43793, 5474, 5475)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news, train_labels, train_images = train_data['title'].tolist(), train_data['6_way_label'].tolist(), train_data['id'].tolist()\n",
    "valid_news, valid_labels, valid_images = valid_data['title'].tolist(), valid_data['6_way_label'].tolist(), valid_data['id'].tolist()\n",
    "test_news, test_labels, test_images = test_data['title'].tolist(), test_data['6_way_label'].tolist(), test_data['id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix(images, suffix='.jpg'):\n",
    "    return [image + suffix for image in images]\n",
    "\n",
    "train_images_final = add_suffix(train_images)\n",
    "valid_images_final = add_suffix(valid_images)\n",
    "test_images_final = add_suffix(test_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center'> Preparing the text data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(sentence):\n",
    "    return re.sub(r'[^a-zA-Z\\s]|\\s+', ' ', sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news_clean = [preprocess_text(new) for new in train_news]\n",
    "valid_news_clean = [preprocess_text(new) for new in valid_news]\n",
    "test_news_clean = [preprocess_text(new) for new in test_news]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def remove_stopwords_lem(text):\n",
    "    text = word_tokenize(text)\n",
    "    filtered_words = [lemmatizer.lemmatize(word, pos = get_wordnet_pos(word)) for word in text if word not in stop_words]\n",
    "    filtered_words\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1]\n",
    "    tag\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "train_stwrd_lem = [remove_stopwords_lem(new) for new in train_news_clean]\n",
    "valid_stwrd_lem = [remove_stopwords_lem(new) for new in valid_news_clean]\n",
    "test_stwrd_lem = [remove_stopwords_lem(new) for new in test_news_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_all = train_stwrd_lem + valid_stwrd_lem + test_stwrd_lem\n",
    "tokenizer = Tokenizer(num_words = 128022)\n",
    "tokenizer.fit_on_texts(news_all)\n",
    "train_tokenized = tokenizer.texts_to_sequences(train_stwrd_lem)\n",
    "valid_tokenized = tokenizer.texts_to_sequences(valid_stwrd_lem)\n",
    "test_tokenized = tokenizer.texts_to_sequences(test_stwrd_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length:  36538\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Vocabulary length: \", len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_tokenized_padding = pad_sequences(train_tokenized, maxlen = 15, truncating='post', padding='post')\n",
    "\n",
    "valid_tokenized_padding = pad_sequences(valid_tokenized, maxlen = 15, truncating='post', padding='post')\n",
    "\n",
    "test_tokenized_padding = pad_sequences(test_tokenized, maxlen = 15, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedd(filename):\n",
    "    words = []\n",
    "    vectors = []\n",
    "    with open(filename,'r', encoding=\"utf8\") as file:\n",
    "        for line in file:\n",
    "           row = line.split(' ')\n",
    "           vocab = row[0]\n",
    "           embd = list(map(float, row[1:-1]))\n",
    "           words.append(vocab)\n",
    "           vectors.append(embd)\n",
    "           words, vectors\n",
    "    return words, vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_matrix(word_index, vocab, embeddings, vocab_len, embedding_len):\n",
    "    embedding_matrix = np.zeros((vocab_len + 1, embedding_len))\n",
    "    for word, i in word_index.items():\n",
    "        if word in vocab:\n",
    "            idx = vocab.index(word)\n",
    "            vector = embeddings[idx]\n",
    "            vector = np.pad(vector, (0, embedding_len - len(vector)), 'constant')\n",
    "            embedding_matrix[i] = vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_gv_300, vectors_gv_300 = load_embedd(filename = \"glove.6B.300d.txt\") # glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix_gv_300 = embed_matrix(word_index=word_index, vocab=vocab_gv_300, embeddings=vectors_gv_300,\n",
    "vocab_len=110688, embedding_len=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center'> Preparing the image data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length all_images: 54742\n"
     ]
    }
   ],
   "source": [
    "all_images = os.listdir(\"image_dataset/\")\n",
    "path = \"image_dataset/\"\n",
    "\n",
    "\n",
    "print(\"length all_images:\",len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_images(image):\n",
    "    h, w, c = image.shape\n",
    "    img_reshaped = np.zeros((3, 560, 560))\n",
    "    rh = min(h, 560)\n",
    "    rw = min(w, 560)\n",
    "    img_reshaped[0, :rh, :rw] = image[:rh, :rw, 0]\n",
    "    img_reshaped[1, :rh, :rw] = image[:rh, :rw, 1]\n",
    "    img_reshaped[2, :rh, :rw] = image[:rh, :rw, 2]\n",
    "    return img_reshaped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center'> Defining the model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_dimx, nlabels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.title_embedding = nn.Embedding(\n",
    "            num_embeddings=110688,\n",
    "            embedding_dim=300\n",
    "        )\n",
    "        self.title_embedding.weight = nn.Parameter(\n",
    "            torch.from_numpy(embedding_matrix_gv_300),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        self.image_cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 3, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.title_cnn = nn.ModuleList([\n",
    "            nn.Conv2d(1, 50, (k, 300), padding=(k-1,0))\n",
    "            for k in [2, 3, 4, 5]\n",
    "        ])\n",
    "        \n",
    "        self.fc1 = nn.Linear(200 + 3 * 137 * 137, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, nlabels)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.final_image_dim = int(((image_dimx - 4) / 2 - 4) / 2)\n",
    "\n",
    "    def forward(self, image, title):\n",
    "        image = self.image_cnn(image)\n",
    "        image = image.view(image.shape[0], self.final_image_dim * self.final_image_dim * 3)\n",
    "\n",
    "        title = self.title_embedding(title)\n",
    "        title = title.unsqueeze(1)\n",
    "        title = [F.relu(conv(title.float())).squeeze(3) for conv in self.title_cnn]\n",
    "        title = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in title] \n",
    "        title = torch.cat(title, 1)\n",
    "        \n",
    "        x = torch.cat([image, title], 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(image_dimx=560, nlabels=6).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center'> Training the Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch Processed:  1\n",
      "Training Batch Processed:  2\n",
      "Training Batch Processed:  3\n",
      "Training Batch Processed:  4\n",
      "Training Batch Processed:  5\n",
      "Training Batch Processed:  6\n",
      "Training Batch Processed:  7\n",
      "Training Batch Processed:  8\n",
      "Training Batch Processed:  9\n",
      "Training Batch Processed:  10\n",
      "Training Batch Processed:  11\n",
      "Training Batch Processed:  12\n",
      "Training Batch Processed:  13\n",
      "Training Batch Processed:  14\n",
      "Training Batch Processed:  15\n",
      "Training Batch Processed:  16\n",
      "Training Batch Processed:  17\n",
      "Training Batch Processed:  18\n",
      "Training Batch Processed:  19\n",
      "Training Batch Processed:  20\n",
      "Training Batch Processed:  21\n",
      "Training Batch Processed:  22\n",
      "Training Batch Processed:  23\n",
      "Training Batch Processed:  24\n",
      "Training Batch Processed:  25\n",
      "Training Batch Processed:  26\n",
      "Training Batch Processed:  27\n",
      "Training Batch Processed:  28\n",
      "Training Batch Processed:  29\n",
      "Training Batch Processed:  30\n",
      "Training Batch Processed:  31\n",
      "Training Batch Processed:  32\n",
      "Training Batch Processed:  33\n",
      "Training Batch Processed:  34\n",
      "Training Batch Processed:  35\n",
      "Training Batch Processed:  36\n",
      "Training Batch Processed:  37\n",
      "Training Batch Processed:  38\n",
      "Training Batch Processed:  39\n",
      "Training Batch Processed:  40\n",
      "Training Batch Processed:  41\n",
      "Training Batch Processed:  42\n",
      "Training Batch Processed:  43\n",
      "Training Batch Processed:  44\n",
      "Training Batch Processed:  45\n",
      "Training Batch Processed:  46\n",
      "Training Batch Processed:  47\n",
      "Training Batch Processed:  48\n",
      "Training Batch Processed:  49\n",
      "Training Batch Processed:  50\n",
      "Training Batch Processed:  51\n",
      "Training Batch Processed:  52\n",
      "Training Batch Processed:  53\n",
      "Training Batch Processed:  54\n",
      "Training Batch Processed:  55\n",
      "Training Batch Processed:  56\n",
      "Training Batch Processed:  57\n",
      "Training Batch Processed:  58\n",
      "Training Batch Processed:  59\n",
      "Training Batch Processed:  60\n",
      "Training Batch Processed:  61\n",
      "Training Batch Processed:  62\n",
      "Training Batch Processed:  63\n",
      "Training Batch Processed:  64\n",
      "Training Batch Processed:  65\n",
      "Training Batch Processed:  66\n",
      "Training Batch Processed:  67\n",
      "Training Batch Processed:  68\n",
      "Training Batch Processed:  69\n",
      "Training Batch Processed:  70\n",
      "Training Batch Processed:  71\n",
      "Training Batch Processed:  72\n",
      "Training Batch Processed:  73\n",
      "Training Batch Processed:  74\n",
      "Training Batch Processed:  75\n",
      "Training Batch Processed:  76\n",
      "Training Batch Processed:  77\n",
      "Training Batch Processed:  78\n",
      "Training Batch Processed:  79\n",
      "Training Batch Processed:  80\n",
      "Training Batch Processed:  81\n",
      "Training Batch Processed:  82\n",
      "Training Batch Processed:  83\n",
      "Training Batch Processed:  84\n",
      "Training Batch Processed:  85\n",
      "Training Batch Processed:  86\n",
      "Training Batch Processed:  87\n",
      "Training Batch Processed:  88\n",
      "Training Batch Processed:  89\n",
      "Training Batch Processed:  90\n",
      "Training Batch Processed:  91\n",
      "Training Batch Processed:  92\n",
      "Training Batch Processed:  93\n",
      "Training Batch Processed:  94\n",
      "Training Batch Processed:  95\n",
      "Training Batch Processed:  96\n",
      "Training Batch Processed:  97\n",
      "Training Batch Processed:  98\n",
      "Training Batch Processed:  99\n",
      "Training Batch Processed:  100\n",
      "Average Training Accuracy: tensor(0.4722)\n",
      "Training Batch Processed:  101\n",
      "Training Batch Processed:  102\n",
      "Training Batch Processed:  103\n",
      "Training Batch Processed:  104\n",
      "Training Batch Processed:  105\n",
      "Training Batch Processed:  106\n",
      "Training Batch Processed:  107\n",
      "Training Batch Processed:  108\n",
      "Training Batch Processed:  109\n",
      "Training Batch Processed:  110\n",
      "Training Batch Processed:  111\n",
      "Training Batch Processed:  112\n",
      "Training Batch Processed:  113\n",
      "Training Batch Processed:  114\n",
      "Training Batch Processed:  115\n",
      "Training Batch Processed:  116\n",
      "Training Batch Processed:  117\n",
      "Training Batch Processed:  118\n",
      "Training Batch Processed:  119\n",
      "Training Batch Processed:  120\n",
      "Training Batch Processed:  121\n",
      "Training Batch Processed:  122\n",
      "Training Batch Processed:  123\n",
      "Training Batch Processed:  124\n",
      "Training Batch Processed:  125\n",
      "Training Batch Processed:  126\n",
      "Training Batch Processed:  127\n",
      "Training Batch Processed:  128\n",
      "Training Batch Processed:  129\n",
      "Training Batch Processed:  130\n",
      "Training Batch Processed:  131\n",
      "Training Batch Processed:  132\n",
      "Training Batch Processed:  133\n",
      "Training Batch Processed:  134\n",
      "Training Batch Processed:  135\n",
      "Training Batch Processed:  136\n",
      "Training Batch Processed:  137\n",
      "Training Batch Processed:  138\n",
      "Training Batch Processed:  139\n",
      "Training Batch Processed:  140\n",
      "Training Batch Processed:  141\n",
      "Training Batch Processed:  142\n",
      "Training Batch Processed:  143\n",
      "Training Batch Processed:  144\n",
      "Training Batch Processed:  145\n",
      "Training Batch Processed:  146\n",
      "Training Batch Processed:  147\n",
      "Training Batch Processed:  148\n",
      "Training Batch Processed:  149\n",
      "Training Batch Processed:  150\n",
      "Training Batch Processed:  151\n",
      "Training Batch Processed:  152\n",
      "Training Batch Processed:  153\n",
      "Training Batch Processed:  154\n",
      "Training Batch Processed:  155\n",
      "Training Batch Processed:  156\n",
      "Training Batch Processed:  157\n",
      "Training Batch Processed:  158\n",
      "Training Batch Processed:  159\n",
      "Training Batch Processed:  160\n",
      "Training Batch Processed:  161\n",
      "Training Batch Processed:  162\n",
      "Training Batch Processed:  163\n",
      "Training Batch Processed:  164\n",
      "Training Batch Processed:  165\n",
      "Training Batch Processed:  166\n",
      "Training Batch Processed:  167\n",
      "Training Batch Processed:  168\n",
      "Training Batch Processed:  169\n",
      "Training Batch Processed:  170\n",
      "Training Batch Processed:  171\n",
      "Training Batch Processed:  172\n",
      "Training Batch Processed:  173\n",
      "Training Batch Processed:  174\n",
      "Training Batch Processed:  175\n",
      "Training Batch Processed:  176\n",
      "Training Batch Processed:  177\n",
      "Training Batch Processed:  178\n",
      "Training Batch Processed:  179\n",
      "Training Batch Processed:  180\n",
      "Training Batch Processed:  181\n",
      "Training Batch Processed:  182\n",
      "Training Batch Processed:  183\n",
      "Training Batch Processed:  184\n",
      "Training Batch Processed:  185\n",
      "Training Batch Processed:  186\n",
      "Training Batch Processed:  187\n",
      "Training Batch Processed:  188\n",
      "Training Batch Processed:  189\n",
      "Training Batch Processed:  190\n",
      "Training Batch Processed:  191\n",
      "Training Batch Processed:  192\n",
      "Training Batch Processed:  193\n",
      "Training Batch Processed:  194\n",
      "Training Batch Processed:  195\n",
      "Training Batch Processed:  196\n",
      "Training Batch Processed:  197\n",
      "Training Batch Processed:  198\n",
      "Training Batch Processed:  199\n",
      "Training Batch Processed:  200\n",
      "Average Training Accuracy: tensor(0.5395)\n",
      "Training Batch Processed:  201\n",
      "Training Batch Processed:  202\n",
      "Training Batch Processed:  203\n",
      "Training Batch Processed:  204\n",
      "Training Batch Processed:  205\n",
      "Training Batch Processed:  206\n",
      "Training Batch Processed:  207\n",
      "Training Batch Processed:  208\n",
      "Training Batch Processed:  209\n",
      "Training Batch Processed:  210\n",
      "Training Batch Processed:  211\n",
      "Training Batch Processed:  212\n",
      "Training Batch Processed:  213\n",
      "Training Batch Processed:  214\n",
      "Training Batch Processed:  215\n",
      "Training Batch Processed:  216\n",
      "Training Batch Processed:  217\n",
      "Training Batch Processed:  218\n",
      "Training Batch Processed:  219\n",
      "Training Batch Processed:  220\n",
      "Training Batch Processed:  221\n",
      "Training Batch Processed:  222\n",
      "Training Batch Processed:  223\n",
      "Training Batch Processed:  224\n",
      "Training Batch Processed:  225\n",
      "Training Batch Processed:  226\n",
      "Training Batch Processed:  227\n",
      "Training Batch Processed:  228\n",
      "Training Batch Processed:  229\n",
      "Training Batch Processed:  230\n",
      "Training Batch Processed:  231\n",
      "Training Batch Processed:  232\n",
      "Training Batch Processed:  233\n",
      "Training Batch Processed:  234\n",
      "Training Batch Processed:  235\n",
      "Training Batch Processed:  236\n",
      "Training Batch Processed:  237\n",
      "Training Batch Processed:  238\n",
      "Training Batch Processed:  239\n",
      "Training Batch Processed:  240\n",
      "Training Batch Processed:  241\n",
      "Training Batch Processed:  242\n",
      "Training Batch Processed:  243\n",
      "Training Batch Processed:  244\n",
      "Training Batch Processed:  245\n",
      "Training Batch Processed:  246\n",
      "Training Batch Processed:  247\n",
      "Training Batch Processed:  248\n",
      "Training Batch Processed:  249\n",
      "Training Batch Processed:  250\n",
      "Training Batch Processed:  251\n",
      "Training Batch Processed:  252\n",
      "Training Batch Processed:  253\n",
      "Training Batch Processed:  254\n",
      "Training Batch Processed:  255\n",
      "Training Batch Processed:  256\n",
      "Training Batch Processed:  257\n",
      "Training Batch Processed:  258\n",
      "Training Batch Processed:  259\n",
      "Training Batch Processed:  260\n",
      "Training Batch Processed:  261\n",
      "Training Batch Processed:  262\n",
      "Training Batch Processed:  263\n",
      "Training Batch Processed:  264\n",
      "Training Batch Processed:  265\n",
      "Training Batch Processed:  266\n",
      "Training Batch Processed:  267\n",
      "Training Batch Processed:  268\n",
      "Training Batch Processed:  269\n",
      "Training Batch Processed:  270\n",
      "Training Batch Processed:  271\n",
      "Training Batch Processed:  272\n",
      "Training Batch Processed:  273\n",
      "Training Batch Processed:  274\n",
      "Training Batch Processed:  275\n",
      "Training Batch Processed:  276\n",
      "Training Batch Processed:  277\n",
      "Training Batch Processed:  278\n",
      "Training Batch Processed:  279\n",
      "Training Batch Processed:  280\n",
      "Training Batch Processed:  281\n",
      "Training Batch Processed:  282\n",
      "Training Batch Processed:  283\n",
      "Training Batch Processed:  284\n",
      "Training Batch Processed:  285\n",
      "Training Batch Processed:  286\n",
      "Training Batch Processed:  287\n",
      "Training Batch Processed:  288\n",
      "Training Batch Processed:  289\n",
      "Training Batch Processed:  290\n",
      "Training Batch Processed:  291\n",
      "Training Batch Processed:  292\n",
      "Training Batch Processed:  293\n",
      "Training Batch Processed:  294\n",
      "Training Batch Processed:  295\n",
      "Training Batch Processed:  296\n",
      "Training Batch Processed:  297\n",
      "Training Batch Processed:  298\n",
      "Training Batch Processed:  299\n",
      "Training Batch Processed:  300\n",
      "Average Training Accuracy: tensor(0.5786)\n",
      "Training Batch Processed:  301\n",
      "Training Batch Processed:  302\n",
      "Training Batch Processed:  303\n",
      "Training Batch Processed:  304\n",
      "Training Batch Processed:  305\n",
      "Training Batch Processed:  306\n",
      "Training Batch Processed:  307\n",
      "Training Batch Processed:  308\n",
      "Training Batch Processed:  309\n",
      "Training Batch Processed:  310\n",
      "Training Batch Processed:  311\n",
      "Training Batch Processed:  312\n",
      "Training Batch Processed:  313\n",
      "Training Batch Processed:  314\n",
      "Training Batch Processed:  315\n",
      "Training Batch Processed:  316\n",
      "Training Batch Processed:  317\n",
      "Training Batch Processed:  318\n",
      "Training Batch Processed:  319\n",
      "Training Batch Processed:  320\n",
      "Training Batch Processed:  321\n",
      "Training Batch Processed:  322\n",
      "Training Batch Processed:  323\n",
      "Training Batch Processed:  324\n",
      "Training Batch Processed:  325\n",
      "Training Batch Processed:  326\n",
      "Training Batch Processed:  327\n",
      "Training Batch Processed:  328\n",
      "Training Batch Processed:  329\n",
      "Training Batch Processed:  330\n",
      "Training Batch Processed:  331\n",
      "Training Batch Processed:  332\n",
      "Training Batch Processed:  333\n",
      "Training Batch Processed:  334\n",
      "Training Batch Processed:  335\n",
      "Training Batch Processed:  336\n",
      "Training Batch Processed:  337\n",
      "Training Batch Processed:  338\n",
      "Training Batch Processed:  339\n",
      "Training Batch Processed:  340\n",
      "Training Batch Processed:  341\n",
      "Training Batch Processed:  342\n",
      "Training Batch Processed:  343\n",
      "Training Batch Processed:  344\n",
      "Training Batch Processed:  345\n",
      "Training Batch Processed:  346\n",
      "Training Batch Processed:  347\n",
      "Training Batch Processed:  348\n",
      "Training Batch Processed:  349\n",
      "Training Batch Processed:  350\n",
      "Training Batch Processed:  351\n",
      "Training Batch Processed:  352\n",
      "Training Batch Processed:  353\n",
      "Training Batch Processed:  354\n",
      "Training Batch Processed:  355\n",
      "Training Batch Processed:  356\n",
      "Training Batch Processed:  357\n",
      "Training Batch Processed:  358\n",
      "Training Batch Processed:  359\n",
      "Training Batch Processed:  360\n",
      "Training Batch Processed:  361\n",
      "Training Batch Processed:  362\n",
      "Training Batch Processed:  363\n",
      "Training Batch Processed:  364\n",
      "Training Batch Processed:  365\n",
      "Training Batch Processed:  366\n",
      "Training Batch Processed:  367\n",
      "Training Batch Processed:  368\n",
      "Training Batch Processed:  369\n",
      "Training Batch Processed:  370\n",
      "Training Batch Processed:  371\n",
      "Training Batch Processed:  372\n",
      "Training Batch Processed:  373\n",
      "Training Batch Processed:  374\n",
      "Training Batch Processed:  375\n",
      "Training Batch Processed:  376\n",
      "Training Batch Processed:  377\n",
      "Training Batch Processed:  378\n",
      "Training Batch Processed:  379\n",
      "Training Batch Processed:  380\n",
      "Training Batch Processed:  381\n",
      "Training Batch Processed:  382\n",
      "Training Batch Processed:  383\n",
      "Training Batch Processed:  384\n",
      "Training Batch Processed:  385\n",
      "Training Batch Processed:  386\n",
      "Training Batch Processed:  387\n",
      "Training Batch Processed:  388\n",
      "Training Batch Processed:  389\n",
      "Training Batch Processed:  390\n",
      "Training Batch Processed:  391\n",
      "Training Batch Processed:  392\n",
      "Training Batch Processed:  393\n",
      "Training Batch Processed:  394\n",
      "Training Batch Processed:  395\n",
      "Training Batch Processed:  396\n",
      "Training Batch Processed:  397\n",
      "Training Batch Processed:  398\n",
      "Training Batch Processed:  399\n",
      "Training Batch Processed:  400\n",
      "Average Training Accuracy: tensor(0.6072)\n",
      "Training Batch Processed:  401\n",
      "Training Batch Processed:  402\n",
      "Training Batch Processed:  403\n",
      "Training Batch Processed:  404\n",
      "Training Batch Processed:  405\n",
      "Training Batch Processed:  406\n",
      "Training Batch Processed:  407\n",
      "Training Batch Processed:  408\n",
      "Training Batch Processed:  409\n",
      "Training Batch Processed:  410\n",
      "Training Batch Processed:  411\n",
      "Training Batch Processed:  412\n",
      "Training Batch Processed:  413\n",
      "Training Batch Processed:  414\n",
      "Training Batch Processed:  415\n",
      "Training Batch Processed:  416\n",
      "Training Batch Processed:  417\n",
      "Training Batch Processed:  418\n",
      "Training Batch Processed:  419\n",
      "Training Batch Processed:  420\n",
      "Training Batch Processed:  421\n",
      "Training Batch Processed:  422\n",
      "Training Batch Processed:  423\n",
      "Training Batch Processed:  424\n",
      "Training Batch Processed:  425\n",
      "Training Batch Processed:  426\n",
      "Training Batch Processed:  427\n",
      "Training Batch Processed:  428\n",
      "Training Batch Processed:  429\n",
      "Training Batch Processed:  430\n",
      "Training Batch Processed:  431\n",
      "Training Batch Processed:  432\n",
      "Training Batch Processed:  433\n",
      "Training Batch Processed:  434\n",
      "Training Batch Processed:  435\n",
      "Training Batch Processed:  436\n",
      "Training Batch Processed:  437\n",
      "Training Batch Processed:  438\n",
      "Training Batch Processed:  439\n",
      "Training Batch Processed:  440\n",
      "Training Batch Processed:  441\n",
      "Training Batch Processed:  442\n",
      "Training Batch Processed:  443\n",
      "Training Batch Processed:  444\n",
      "Training Batch Processed:  445\n",
      "Training Batch Processed:  446\n",
      "Training Batch Processed:  447\n",
      "Training Batch Processed:  448\n",
      "Training Batch Processed:  449\n",
      "Training Batch Processed:  450\n",
      "Training Batch Processed:  451\n",
      "Training Batch Processed:  452\n",
      "Training Batch Processed:  453\n",
      "Training Batch Processed:  454\n",
      "Training Batch Processed:  455\n",
      "Training Batch Processed:  456\n",
      "Training Batch Processed:  457\n",
      "Training Batch Processed:  458\n",
      "Training Batch Processed:  459\n",
      "Training Batch Processed:  460\n",
      "Training Batch Processed:  461\n",
      "Training Batch Processed:  462\n",
      "Training Batch Processed:  463\n",
      "Training Batch Processed:  464\n",
      "Training Batch Processed:  465\n",
      "Training Batch Processed:  466\n",
      "Training Batch Processed:  467\n",
      "Training Batch Processed:  468\n",
      "Training Batch Processed:  469\n",
      "Training Batch Processed:  470\n",
      "Training Batch Processed:  471\n",
      "Training Batch Processed:  472\n",
      "Training Batch Processed:  473\n",
      "Training Batch Processed:  474\n",
      "Training Batch Processed:  475\n",
      "Training Batch Processed:  476\n",
      "Training Batch Processed:  477\n",
      "Training Batch Processed:  478\n",
      "Training Batch Processed:  479\n",
      "Training Batch Processed:  480\n",
      "Training Batch Processed:  481\n",
      "Training Batch Processed:  482\n",
      "Training Batch Processed:  483\n",
      "Training Batch Processed:  484\n",
      "Training Batch Processed:  485\n",
      "Training Batch Processed:  486\n",
      "Training Batch Processed:  487\n",
      "Training Batch Processed:  488\n",
      "Training Batch Processed:  489\n",
      "Training Batch Processed:  490\n",
      "Training Batch Processed:  491\n",
      "Training Batch Processed:  492\n",
      "Training Batch Processed:  493\n",
      "Training Batch Processed:  494\n",
      "Training Batch Processed:  495\n",
      "Training Batch Processed:  496\n",
      "Training Batch Processed:  497\n",
      "Training Batch Processed:  498\n",
      "Training Batch Processed:  499\n",
      "Training Batch Processed:  500\n",
      "Average Training Accuracy: tensor(0.6249)\n",
      "Training Batch Processed:  501\n",
      "Training Batch Processed:  502\n",
      "Training Batch Processed:  503\n",
      "Training Batch Processed:  504\n",
      "Training Batch Processed:  505\n",
      "Training Batch Processed:  506\n",
      "Training Batch Processed:  507\n",
      "Training Batch Processed:  508\n",
      "Training Batch Processed:  509\n",
      "Training Batch Processed:  510\n",
      "Training Batch Processed:  511\n",
      "Training Batch Processed:  512\n",
      "Training Batch Processed:  513\n",
      "Training Batch Processed:  514\n",
      "Training Batch Processed:  515\n",
      "Training Batch Processed:  516\n",
      "Training Batch Processed:  517\n",
      "Training Batch Processed:  518\n",
      "Training Batch Processed:  519\n",
      "Training Batch Processed:  520\n",
      "Training Batch Processed:  521\n",
      "Training Batch Processed:  522\n",
      "Training Batch Processed:  523\n",
      "Training Batch Processed:  524\n",
      "Training Batch Processed:  525\n",
      "Training Batch Processed:  526\n",
      "Training Batch Processed:  527\n",
      "Training Batch Processed:  528\n",
      "Training Batch Processed:  529\n",
      "Training Batch Processed:  530\n",
      "Training Batch Processed:  531\n",
      "Training Batch Processed:  532\n",
      "Training Batch Processed:  533\n",
      "Training Batch Processed:  534\n",
      "Training Batch Processed:  535\n",
      "Training Batch Processed:  536\n",
      "Training Batch Processed:  537\n",
      "Training Batch Processed:  538\n",
      "Training Batch Processed:  539\n",
      "Training Batch Processed:  540\n",
      "Training Batch Processed:  541\n",
      "Training Batch Processed:  542\n",
      "Training Batch Processed:  543\n",
      "Training Batch Processed:  544\n",
      "Training Batch Processed:  545\n",
      "Training Batch Processed:  546\n",
      "Training Batch Processed:  547\n",
      "Training Batch Processed:  548\n",
      "Training Batch Processed:  549\n",
      "Training Batch Processed:  550\n",
      "Training Batch Processed:  551\n",
      "Training Batch Processed:  552\n",
      "Training Batch Processed:  553\n",
      "Training Batch Processed:  554\n",
      "Training Batch Processed:  555\n",
      "Training Batch Processed:  556\n",
      "Training Batch Processed:  557\n",
      "Training Batch Processed:  558\n",
      "Training Batch Processed:  559\n",
      "Training Batch Processed:  560\n",
      "Training Batch Processed:  561\n",
      "Training Batch Processed:  562\n",
      "Training Batch Processed:  563\n",
      "Training Batch Processed:  564\n",
      "Training Batch Processed:  565\n",
      "Training Batch Processed:  566\n",
      "Training Batch Processed:  567\n",
      "Training Batch Processed:  568\n",
      "Training Batch Processed:  569\n",
      "Training Batch Processed:  570\n",
      "Training Batch Processed:  571\n",
      "Training Batch Processed:  572\n",
      "Training Batch Processed:  573\n",
      "Training Batch Processed:  574\n",
      "Training Batch Processed:  575\n",
      "Training Batch Processed:  576\n",
      "Training Batch Processed:  577\n",
      "Training Batch Processed:  578\n",
      "Training Batch Processed:  579\n",
      "Training Batch Processed:  580\n",
      "Training Batch Processed:  581\n",
      "Training Batch Processed:  582\n",
      "Training Batch Processed:  583\n",
      "Training Batch Processed:  584\n",
      "Training Batch Processed:  585\n",
      "Training Batch Processed:  586\n",
      "Training Batch Processed:  587\n",
      "Training Batch Processed:  588\n",
      "Training Batch Processed:  589\n",
      "Training Batch Processed:  590\n",
      "Training Batch Processed:  591\n",
      "Training Batch Processed:  592\n",
      "Training Batch Processed:  593\n",
      "Training Batch Processed:  594\n",
      "Training Batch Processed:  595\n",
      "Training Batch Processed:  596\n",
      "Training Batch Processed:  597\n",
      "Training Batch Processed:  598\n",
      "Training Batch Processed:  599\n",
      "Training Batch Processed:  600\n",
      "Average Training Accuracy: tensor(0.6404)\n",
      "Training Batch Processed:  601\n",
      "Training Batch Processed:  602\n",
      "Training Batch Processed:  603\n",
      "Training Batch Processed:  604\n",
      "Training Batch Processed:  605\n",
      "Training Batch Processed:  606\n",
      "Training Batch Processed:  607\n",
      "Training Batch Processed:  608\n",
      "Training Batch Processed:  609\n",
      "Training Batch Processed:  610\n",
      "Training Batch Processed:  611\n",
      "Training Batch Processed:  612\n",
      "Training Batch Processed:  613\n",
      "Training Batch Processed:  614\n",
      "Training Batch Processed:  615\n",
      "Training Batch Processed:  616\n",
      "Training Batch Processed:  617\n",
      "Training Batch Processed:  618\n",
      "Training Batch Processed:  619\n",
      "Training Batch Processed:  620\n",
      "Training Batch Processed:  621\n",
      "Training Batch Processed:  622\n",
      "Training Batch Processed:  623\n",
      "Training Batch Processed:  624\n",
      "Training Batch Processed:  625\n",
      "Training Batch Processed:  626\n",
      "Training Batch Processed:  627\n",
      "Training Batch Processed:  628\n",
      "Training Batch Processed:  629\n",
      "Training Batch Processed:  630\n",
      "Training Batch Processed:  631\n",
      "Training Batch Processed:  632\n",
      "Training Batch Processed:  633\n",
      "Training Batch Processed:  634\n",
      "Training Batch Processed:  635\n",
      "Training Batch Processed:  636\n",
      "Training Batch Processed:  637\n",
      "Training Batch Processed:  638\n",
      "Training Batch Processed:  639\n",
      "Training Batch Processed:  640\n",
      "Training Batch Processed:  641\n",
      "Training Batch Processed:  642\n",
      "Training Batch Processed:  643\n",
      "Training Batch Processed:  644\n",
      "Training Batch Processed:  645\n",
      "Training Batch Processed:  646\n",
      "Training Batch Processed:  647\n",
      "Training Batch Processed:  648\n",
      "Training Batch Processed:  649\n",
      "Training Batch Processed:  650\n",
      "Training Batch Processed:  651\n",
      "Training Batch Processed:  652\n",
      "Training Batch Processed:  653\n",
      "Training Batch Processed:  654\n",
      "Training Batch Processed:  655\n",
      "Training Batch Processed:  656\n",
      "Training Batch Processed:  657\n",
      "Training Batch Processed:  658\n",
      "Training Batch Processed:  659\n",
      "Training Batch Processed:  660\n",
      "Training Batch Processed:  661\n",
      "Training Batch Processed:  662\n",
      "Training Batch Processed:  663\n",
      "Training Batch Processed:  664\n",
      "Training Batch Processed:  665\n",
      "Training Batch Processed:  666\n",
      "Training Batch Processed:  667\n",
      "Training Batch Processed:  668\n",
      "Training Batch Processed:  669\n",
      "Training Batch Processed:  670\n",
      "Training Batch Processed:  671\n",
      "Training Batch Processed:  672\n",
      "Training Batch Processed:  673\n",
      "Training Batch Processed:  674\n",
      "Training Batch Processed:  675\n",
      "Training Batch Processed:  676\n",
      "Training Batch Processed:  677\n",
      "Training Batch Processed:  678\n",
      "Training Batch Processed:  679\n",
      "Training Batch Processed:  680\n",
      "Training Batch Processed:  681\n",
      "Training Batch Processed:  682\n",
      "Training Batch Processed:  683\n",
      "Training Batch Processed:  684\n",
      "Training Batch Processed:  685\n",
      "Training Batch Processed:  686\n",
      "Training Batch Processed:  687\n",
      "Training Batch Processed:  688\n",
      "Training Batch Processed:  689\n",
      "Training Batch Processed:  690\n",
      "Training Batch Processed:  691\n",
      "Training Batch Processed:  692\n",
      "Training Batch Processed:  693\n",
      "Training Batch Processed:  694\n",
      "Training Batch Processed:  695\n",
      "Training Batch Processed:  696\n",
      "Training Batch Processed:  697\n",
      "Training Batch Processed:  698\n",
      "Training Batch Processed:  699\n",
      "Training Batch Processed:  700\n",
      "Average Training Accuracy: tensor(0.6526)\n",
      "Training Batch Processed:  701\n",
      "Training Batch Processed:  702\n",
      "Training Batch Processed:  703\n",
      "Training Batch Processed:  704\n",
      "Training Batch Processed:  705\n",
      "Training Batch Processed:  706\n",
      "Training Batch Processed:  707\n",
      "Training Batch Processed:  708\n",
      "Training Batch Processed:  709\n",
      "Training Batch Processed:  710\n",
      "Training Batch Processed:  711\n",
      "Training Batch Processed:  712\n",
      "Training Batch Processed:  713\n",
      "Training Batch Processed:  714\n",
      "Training Batch Processed:  715\n",
      "Training Batch Processed:  716\n",
      "Training Batch Processed:  717\n",
      "Training Batch Processed:  718\n",
      "Training Batch Processed:  719\n",
      "Training Batch Processed:  720\n",
      "Training Batch Processed:  721\n",
      "Training Batch Processed:  722\n",
      "Training Batch Processed:  723\n",
      "Training Batch Processed:  724\n",
      "Training Batch Processed:  725\n",
      "Training Batch Processed:  726\n",
      "Training Batch Processed:  727\n",
      "Training Batch Processed:  728\n",
      "Training Batch Processed:  729\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "train_accuracy = 0\n",
    "train_batches_processed = 0\n",
    "\n",
    "images_tensor = torch.zeros(60, 3, 560, 560)\n",
    "titles_tensor = torch.zeros(60, 15)\n",
    "labels_tensor = torch.zeros(60)\n",
    "\n",
    "images_tensor = images_tensor.to(device)\n",
    "titles_tensor = titles_tensor.to(device)\n",
    "labels_tensor = labels_tensor.to(device)\n",
    "\n",
    "for i in range(len(train_images_final)):\n",
    "    \n",
    "    img = cv2.imread(os.path.join(path, train_images_final[i])) \n",
    "        \n",
    "    if type(img) is not type(None):\n",
    "        counter += 1 \n",
    "        \n",
    "        img_padded = pad_images(img)\n",
    "\n",
    "        images_tensor = images_tensor.to(device)\n",
    "        titles_tensor = titles_tensor.to(device)\n",
    "        labels_tensor = labels_tensor.to(device)\n",
    "        \n",
    "        images_tensor[counter-1, :,:,:] = torch.from_numpy(img_padded)\n",
    "        titles_tensor[counter-1, :] = torch.from_numpy(train_tokenized_padding[i]).int()\n",
    "        labels_tensor[counter - 1] = train_labels[i]\n",
    "           \n",
    "        \n",
    "        if counter % 60 == 0: \n",
    "            train_batches_processed += 1\n",
    "            print(\"Training Batch Processed: \", train_batches_processed)\n",
    "\n",
    "            images_tensor = images_tensor.to(device)\n",
    "            titles_tensor = titles_tensor.to(device)\n",
    "            labels_tensor = labels_tensor.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            out = model.forward(images_tensor, titles_tensor.long())            \n",
    "            loss = criterion(out, labels_tensor.long())\n",
    "            \n",
    "            loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            \n",
    "            top_p, top_class = out.topk(1, dim=1) \n",
    "            equals = (top_class == labels_tensor.view(images_tensor.shape[0], 1))\n",
    "            train_accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "            images_tensor = torch.zeros(60, 3, 560, 560)\n",
    "            titles_tensor = torch.zeros(60, 15)\n",
    "            labels_tensor = torch.zeros(60)\n",
    "            \n",
    "            counter = 0 \n",
    "                \n",
    "            if train_batches_processed % 100 == 0:\n",
    "\n",
    "                print(\"Average Training Accuracy:\", train_accuracy / train_batches_processed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center'> Testing the Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "batch_size = 60\n",
    "images_tensor = torch.zeros(batch_size, 3, 560, 560).to(device)\n",
    "titles_tensor = torch.zeros(batch_size, 15).int().to(device)\n",
    "labels_tensor = torch.zeros(batch_size).int().to(device)\n",
    "\n",
    "predictions = []\n",
    "labels_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_images_final)):\n",
    "        img = cv2.imread(path + test_images_final[i])\n",
    "        if type(img) is not type(None):\n",
    "            counter += 1\n",
    "            img_padded = pad_images(img)\n",
    "            images_tensor[counter - 1, :, :, :] = torch.from_numpy(img_padded).to(device)\n",
    "            titles_tensor[counter - 1, :] = torch.from_numpy(test_tokenized_padding[i]).to(device)\n",
    "            labels_tensor[counter - 1] = test_labels[i]\n",
    "            if counter % batch_size == 0:\n",
    "                out = model(images_tensor, titles_tensor)\n",
    "                top_p, top_class = out.topk(1, dim=1)\n",
    "                predictions.extend(top_class.cpu().numpy().flatten().tolist())\n",
    "                labels_test.extend(labels_tensor.cpu().numpy().tolist())\n",
    "                images_tensor = torch.zeros(batch_size, 3, 560, 560).to(device)\n",
    "                titles_tensor = torch.zeros(batch_size, 15).int().to(device)\n",
    "                labels_tensor = torch.zeros(batch_size).int().to(device)\n",
    "                counter = 0\n",
    "    if counter > 0:\n",
    "        out = model(images_tensor[:counter, ...], titles_tensor[:counter, ...])\n",
    "        top_p, top_class = out.topk(1, dim=1)\n",
    "        predictions.extend(top_class.cpu().numpy().flatten().tolist())\n",
    "        labels_test.extend(labels_tensor[:counter].cpu().numpy().tolist())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "labels_test = np.array(labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(np.array(labels_test).reshape(len(labels_test),1),predictions)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(np.array(labels_test).reshape(len(labels_test),1),predictions)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style='text-align: center'> Saving the Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'week4.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
